import os
import copy
import time
import math
import pickle
import random
import tqdm

import torch
import argparse
import numpy as np
import pandas as pd
import cma
from fastNLP import cache_results, Tester, DataSet
from transformers import (
    RobertaConfig,
    RobertaTokenizer,
    BertConfig,
    BertTokenizer,
    BartConfig,
    BartTokenizer,
    T5Config,
    T5Tokenizer,
    GPT2Config,
    GPT2Tokenizer,
)
from models.deep_modeling_roberta import RobertaForMaskedLM
from models.deep_modeling_bart import BartForConditionalGeneration
from models.deep_modeling_t5 import T5ForConditionalGeneration
from models.deep_modeling_gpt2 import GPT2LMHeadModel
from models.deep_modeling_bert import BertForMaskedLM
from models.deep_modeling_cpt import CPTForMaskedLM
from utils import hinge_loss
from sklearn.metrics import f1_score

import pickle
from scipy.optimize import minimize
from utils import get_multi_verb

parser = argparse.ArgumentParser()
parser.add_argument("--model_name", default='roberta-large',
                    # choices=['roberta-base', 'roberta-large',
                    #          'bert-base-uncased', 'bert-large-uncased',
                    #          'facebook/bart-base', 'facebook/bart-large',
                    #          't5-small', 't5-base', 't5-large', 't5-3b',
                    #          'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl',
                    #          ], 
                    type=str)
parser.add_argument("--model_path", default='roberta-large', type=str, help='The path of hugging face models for offline mode, default=model_name')
parser.add_argument("--task_name", default='AGNews', type=str)
parser.add_argument("--n_prompt_tokens", default=50, type=int)
parser.add_argument("--intrinsic_dim", default=500, type=int)
parser.add_argument("--k_shot", default=16, type=int)
parser.add_argument("--dev_batch_size", default=128, type=int)
parser.add_argument("--dev_sample_num", default=12800, type=int)
parser.add_argument("--budget", default=8000, type=int)
parser.add_argument("--popsize", default=20, type=int)
parser.add_argument("--bound", default=0, type=int)
parser.add_argument("--sigma1", default=1, type=float)
parser.add_argument("--sigma2", default=0.2, type=float)
parser.add_argument("--print_every", default=50, type=int)
parser.add_argument("--eval_every", default=1000, type=int)
parser.add_argument("--device", default='cuda:3', type=str)
parser.add_argument("--alg", default='CMA', type=str)
parser.add_argument("--random_proj", default='normal', type=str)
parser.add_argument("--seed", default=42, type=int)
parser.add_argument("--loss_type", default='ce', type=str)
parser.add_argument(
    "--inference_framework",
    default='pt',
    type=str,
    help='''Which inference framework to use. 
         Currently supports `pt` and `ort`, standing for pytorch and Microsoft onnxruntime respectively'''
)
parser.add_argument(
    "--onnx_model_path",
    default=None,
    type=str,
    help='Path to your onnx model.'
)
parser.add_argument("--prefix", default='last_results', type=str, help="save data dir path prefix.")

# for Data Augmentation
parser.add_argument("--data_dir", default='datasets', type=str, help="'dataset' represents origin datasets, for DA, please select 'DA_datasets'. ")

# DFO

parser.add_argument("--budget2", default=0, type=int, help='two stage hyperparameter,0 refers not to use')
parser.add_argument("--replace_alg", default='COBYLA', type=str, choices=['CMA','openes','PEPG','DFO_tr','Nelder-Mead','Powell','SLSQP','COBYLA','L-BFGS-B'], help='select alg from CMA, openes, PEPG, DFO_tr, Nelder-Mead, Powell, SLSQP, COBYLA, BFGS etc')
parser.add_argument("--pop_mean", default=0, type=int, choices=[0,1], help='0:use result.xbest, 1:use result[5], CMA replace result[0] with mean solution to eval dev, presumably better with noise')


parser.add_argument("--instruction", default=False, action='store_true', help="")
parser.add_argument("--in_contexts", default=False, action='store_true', help="")
parser.add_argument("--multiVerbalizer", default=False, action='store_true', help="multi Verbalizer for TREC.")
# parser.add_argument("--use_tfidf", default=False, action='store_true', help="use tfidf to generate in-contexts.")
parser.add_argument("--sigma_setting", default='bbt2', type=str, help='[bbt2, lin, exp]')
parser.add_argument("--use_rlprompt", default=False, action='store_true', help="use hard prompt generated by rlprompt.")
# parser.add_argument("--dev_best", default=False, action='store_true', help="use dev best.")

args = parser.parse_args()

# below are free hyper-params
model_name = args.model_name
if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
    from dataloader_t5 import SST2Loader, AGNewsLoader, YelpPLoader, MRPCLoader, SNLILoader
    from metrics_t5 import SST2Metric, AGNewsMetric, YelpPMetric, MRPCMetric, SNLIMetric
elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
    from dataloader_gpt import SST2Loader, AGNewsLoader, YelpPLoader, MRPCLoader, SNLILoader
    from metrics_gpt import SST2Metric, AGNewsMetric, YelpPMetric, MRPCMetric, SNLIMetric
else:
    from dataloader import SST2Loader, AGNewsLoader, YelpPLoader, MRPCLoader, SNLILoader, TRECLoader, DBPediaLoader, QNLILoader, QQPLoader
    from metrics import SST2Metric, AGNewsMetric, YelpPMetric, MRPCMetric, SNLIMetric, TRECMetric, DBPediaMetric, QNLIMetric, QQPMetric

model_path = args.model_path
task_name = args.task_name
n_prompt_tokens = args.n_prompt_tokens
intrinsic_dim = args.intrinsic_dim
k_shot = args.k_shot
# batch_size = args.batch_size
budget = args.budget
bound = args.bound
sigma1 = args.sigma1
sigma2 = args.sigma2
if args.popsize > 0:
    popsize = args.popsize
else:
    popsize = 4 + 3 * np.log(intrinsic_dim)
device = args.device
alg = args.alg
random_proj = args.random_proj
seed = args.seed
loss_type = args.loss_type
print_every = args.print_every
eval_every = args.eval_every
# if task_name in ['mrpc', 'snli', 'qnli', 'rte']:
#     args.cat_or_add = 'cat'
inference_framework = args.inference_framework
onnx_model_path = args.onnx_model_path
save_hiddens = True
data_dir = args.data_dir
prefix = args.prefix

budget2 = args.budget2
replace_alg = args.replace_alg

print("###################################")
#for CMA
if alg == 'CMA':
    print("alg:", alg)

# for openes or PEPG
if alg != 'CMA':
    sigma_init = args.sigma_init
    learning_rate = args.learning_rate
    print("alg:", alg)
    print("sigma init, learning rate:", sigma_init, learning_rate)

pop_mean = args.pop_mean
# if pop_mean:
#     budget *= 1 + 1 / (eval_every//popsize - 1)
#     budget = int(budget)

print("pop_mean:", pop_mean)
print("budget:", budget)
print("budget2:", budget2)
print("###################################")

if task_name in ['sst2', 'Yelp', 'MRPC', 'QNLI', 'QQP']:
    num_labels = 2
elif task_name in ['SNLI']:
    num_labels = 3
elif task_name in ['AGNews']:
    num_labels = 4
elif task_name in ['TREC']:
    num_labels = 5
elif task_name in ['DBPedia']:
    num_labels = 14
else:
    raise ValueError

args.bbt_version = 'deepbbt'

random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)

class LMForwardAPI:
    def __init__(self, model_name='roberta-large', model_path='roberta-large', n_prompt_tokens=50, task_name='sst2',
                 loss_type='hinge', args=None):
        self.args = args
        self.model_name = model_name
        self.model_path = model_path
        if model_name in ['roberta-base', 'roberta-large']:
            self.config = RobertaConfig.from_pretrained(model_path)
            self.tokenizer = RobertaTokenizer.from_pretrained(model_path)
            self.model = RobertaForMaskedLM.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
                inference_framework=inference_framework,
                onnx_model_path=onnx_model_path,
            )
            self.model.lm_head.bias = torch.nn.parameter.Parameter(torch.zeros(self.config.vocab_size))
        elif model_name in ['bert-base-uncased', 'bert-large-uncased']:
            self.config = BertConfig.from_pretrained(model_path)
            self.tokenizer = BertTokenizer.from_pretrained(model_path)
            self.model = BertForMaskedLM.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        elif model_name in ['facebook/bart-base', 'facebook/bart-large']:
            self.config = BartConfig.from_pretrained(model_path)
            self.tokenizer = BartTokenizer.from_pretrained(model_path)
            self.model = BartForConditionalGeneration.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        elif model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
            self.config = T5Config.from_pretrained(model_path)
            self.tokenizer = T5Tokenizer.from_pretrained(model_path)
            self.model = T5ForConditionalGeneration.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
            self.config = GPT2Config.from_pretrained(model_path)
            self.tokenizer = GPT2Tokenizer.from_pretrained(model_path)
            self.model = GPT2LMHeadModel.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        elif model_name in ['fnlp/cpt-large']:
            self.config = BartConfig.from_pretrained(model_path)
            self.tokenizer = BertTokenizer.from_pretrained(model_path)
            self.model = CPTForMaskedLM.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        else:
            raise NotImplementedError

        if random_proj == 'normal':
            self.config.output_hidden_states = True

        if inference_framework == 'ort':
            self.model.roberta = None
        self.best_prefix = torch.zeros(self.config.num_hidden_layers, n_prompt_tokens, self.config.hidden_size,
                                       device=device)
        self.best = None
        self.init_prompt = None
        self.model.to(device)
        self.model.eval()
        self.linear = torch.nn.ModuleList(
            [torch.nn.Linear(intrinsic_dim, n_prompt_tokens * self.config.hidden_size, bias=False) for _ in
             range(self.config.num_hidden_layers)])
        if random_proj == 'normal':
            # calculate std for normal distribution
            if model_name in ['roberta-base', 'roberta-large']:
                embedding = self.model.roberta.get_input_embeddings().weight.clone().cpu()
            elif model_name in ['bert-base-uncased', 'bert-large-uncased']:
                embedding = self.model.bert.get_input_embeddings().weight.clone().cpu()
            elif model_name in ['facebook/bart-base', 'facebook/bart-large', 'fnlp/cpt-large']:
                embedding = self.model.model.get_input_embeddings().weight.clone().cpu()
            elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
                embedding = self.model.transformer.get_input_embeddings().weight.clone().cpu()
            else:  # T5
                embedding = self.model.get_input_embeddings().weight.clone().cpu()
            mu_hat = np.mean(embedding.reshape(-1).detach().cpu().numpy())
            std_hat = np.std(embedding.reshape(-1).detach().cpu().numpy())
            mu = 0.0
            std = std_hat / (np.sqrt(intrinsic_dim) * args.sigma1)
            print('[Embedding] mu: {} | std: {} [RandProj]  mu: {} | std: {}'.format(mu_hat, std_hat, mu, std))
            for p in self.linear[0].parameters():
                torch.nn.init.normal_(p, 0.0, std)
            self.intermediate_stats = [(mu, std)]
        self.best_train_perf = 0.0
        self.best_dev_perf = 0.0
        self.num_call = 0
        self.print_every = print_every
        self.eval_every = eval_every
        self.loss_type = loss_type
        self.is_better_dev = self.config.num_hidden_layers * [0]
        if task_name == 'sst2':
            self.metric = SST2Metric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'SST2Metric'
        elif task_name == 'AGNews':
            self.metric = AGNewsMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'AGNewsMetric'
        elif task_name == 'Yelp':
            self.metric = YelpPMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'YelpPMetric'
        elif task_name == 'MRPC':
            self.metric = MRPCMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'MRPCMetric'
        elif task_name == 'SNLI':
            self.metric = SNLIMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'SNLIMetric'
        elif task_name == 'TREC':
            self.metric = TRECMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'TRECMetric'
        elif task_name == 'QNLI':
            self.metric = QNLIMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'QNLIMetric'
        elif task_name == 'QQP':
            self.metric = QQPMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'QQPMetric'
        elif task_name == 'DBPedia':
            self.metric = DBPediaMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'DBPediaMetric'
        else:
            raise NotImplementedError
        self.margin = self.metric.margin
        self.ce_loss = torch.nn.CrossEntropyLoss(reduction='mean')

    def calc_metric(self, logits, target):
        label_map = self.metric.label_map

        converted_target = target.clone()
        for key, val in label_map.items():
            converted_target[target == key] = val
        interest_index = list(label_map.keys())
        logits = logits[:, interest_index]
        pred = logits.argmax(dim=-1)

        if self.metric_key == 'acc':
            perf = (pred == converted_target).sum() / len(target)
        elif self.metric_key == 'f1':
            perf = f1_score(converted_target.detach().cpu().numpy().tolist(),
                            pred.detach().cpu().numpy().tolist(), average='macro')
        else:
            raise KeyError(f'[Metric] Only support [acc, f1], got {self.metric_key} instead.')

        if self.loss_type == 'hinge':
            loss = hinge_loss(logits, converted_target, margin=self.margin, reduction='sum').item() / len(target)
        elif self.loss_type == 'ce':
            loss = self.ce_loss(logits, converted_target).item()
        elif self.loss_type == 'perf':
            loss = -1 * perf
        else:
            raise KeyError(f'[Loss] Only support [hinge, ce, perf], got {self.loss_type} instead.')

        return loss, perf


    def calc_metric_for_multiVerbalizer(self, logits, target):
        if self.args.task_name == 'TREC':
            multi_interest_index = []
            multi_interest_index.append(self.tokenizer.encode("Definition")[1])
            multi_interest_index.append(self.tokenizer.encode("Description")[1])
            multi_interest_index.append(self.tokenizer.encode("Manner")[1])
            multi_interest_index.append(self.tokenizer.encode("Reason")[1])
            multi_interest_index.append(self.tokenizer.encode("Animal")[1])
            multi_interest_index.append(self.tokenizer.encode("Body")[1])
            multi_interest_index.append(self.tokenizer.encode("Color")[1])
            multi_interest_index.append(self.tokenizer.encode("Creative")[1])
            multi_interest_index.append(self.tokenizer.encode("Currency")[1])
            multi_interest_index.append(self.tokenizer.encode("Diseases")[1])
            multi_interest_index.append(self.tokenizer.encode("Medicine")[1])
            multi_interest_index.append(self.tokenizer.encode("Event")[1])
            multi_interest_index.append(self.tokenizer.encode("Food")[1])
            multi_interest_index.append(self.tokenizer.encode("Instrument")[1])
            multi_interest_index.append(self.tokenizer.encode("Lang")[1])
            multi_interest_index.append(self.tokenizer.encode("Letter")[1])
            multi_interest_index.append(self.tokenizer.encode("Entity")[1])
            multi_interest_index.append(self.tokenizer.encode("Plant")[1])
            multi_interest_index.append(self.tokenizer.encode("Product")[1])
            multi_interest_index.append(self.tokenizer.encode("Religion")[1])
            multi_interest_index.append(self.tokenizer.encode("Sport")[1])
            multi_interest_index.append(self.tokenizer.encode("Substance")[1])
            multi_interest_index.append(self.tokenizer.encode("Symbol")[1])
            multi_interest_index.append(self.tokenizer.encode("Technique")[1])
            multi_interest_index.append(self.tokenizer.encode("Term")[1])
            multi_interest_index.append(self.tokenizer.encode("Vehicle")[1])
            multi_interest_index.append(self.tokenizer.encode("Word")[1])
            multi_interest_index.append(self.tokenizer.encode("Abbreviation")[1])
            multi_interest_index.append(self.tokenizer.encode("Expression")[1])
            multi_interest_index.append(self.tokenizer.encode("Group")[1])
            multi_interest_index.append(self.tokenizer.encode("Organization")[1])
            multi_interest_index.append(self.tokenizer.encode("Individual")[1])
            multi_interest_index.append(self.tokenizer.encode("Title")[1])
            multi_interest_index.append(self.tokenizer.encode("Person")[1])
            multi_interest_index.append(self.tokenizer.encode("Human")[1])
            multi_interest_index.append(self.tokenizer.encode("Code")[1])
            multi_interest_index.append(self.tokenizer.encode("Count")[1])
            multi_interest_index.append(self.tokenizer.encode("Date")[1])
            multi_interest_index.append(self.tokenizer.encode("Distance")[1])
            multi_interest_index.append(self.tokenizer.encode("Money")[1])
            multi_interest_index.append(self.tokenizer.encode("Order")[1])
            multi_interest_index.append(self.tokenizer.encode("Number")[1])
            multi_interest_index.append(self.tokenizer.encode("Period")[1])
            multi_interest_index.append(self.tokenizer.encode("Percent")[1])
            multi_interest_index.append(self.tokenizer.encode("Speed")[1])
            multi_interest_index.append(self.tokenizer.encode("Temperature")[1])
            multi_interest_index.append(self.tokenizer.encode("Size")[1])
            multi_interest_index.append(self.tokenizer.encode("Weight")[1])
            multi_interest_index.append(self.tokenizer.encode("Area")[1])
            multi_interest_index.append(self.tokenizer.encode("Volume")[1])
            multi_interest_index.append(self.tokenizer.encode("City")[1])
            multi_interest_index.append(self.tokenizer.encode("Country")[1])
            multi_interest_index.append(self.tokenizer.encode("Mountain")[1])
            multi_interest_index.append(self.tokenizer.encode("Location")[1])
            multi_interest_index.append(self.tokenizer.encode("State")[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :4].mean(dim=1)
            c1 = multi_logits[:, 4:27].mean(dim=1)
            c2 = multi_logits[:, 27:29].mean(dim=1)
            c3 = multi_logits[:, 29:35].mean(dim=1)
            c4 = multi_logits[:, 35:50].mean(dim=1)
            c5 = multi_logits[:, 50:].mean(dim=1)
            logits = torch.stack([c0, c1, c2, c3, c4, c5]).T
        elif self.args.task_name == 'SNLI':
            multi_verb = get_multi_verb(self.args.task_name, self.args.seed)
            multi_interest_index = []
            
            for verb in multi_verb['Entailment']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['Neutral']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['Contradiction']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            # multi_interest_index.append(self.tokenizer.encode("Seriously")[1])
            # multi_interest_index.append(self.tokenizer.encode("Finally")[1])
            # multi_interest_index.append(self.tokenizer.encode("YES")[1])
            # multi_interest_index.append(self.tokenizer.encode("Yeah")[1])
            # multi_interest_index.append(self.tokenizer.encode("Exactly")[1])

            # multi_interest_index.append(self.tokenizer.encode("Now")[1])
            # multi_interest_index.append(self.tokenizer.encode("This")[1])
            # multi_interest_index.append(self.tokenizer.encode("Likely")[1])
            # multi_interest_index.append(self.tokenizer.encode("Apparently")[1])
            # multi_interest_index.append(self.tokenizer.encode("Suddenly")[1])

            # multi_interest_index.append(self.tokenizer.encode("Nah")[1])
            # multi_interest_index.append(self.tokenizer.encode("Next")[1])
            # multi_interest_index.append(self.tokenizer.encode("Alas")[1])
            # multi_interest_index.append(self.tokenizer.encode("Nope")[1])
            # multi_interest_index.append(self.tokenizer.encode("Later")[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :5].mean(dim=1)
            c1 = multi_logits[:, 5:10].mean(dim=1)
            c2 = multi_logits[:, 10:].mean(dim=1)
            logits = torch.stack([c0, c1, c2]).T
            # print('*******Use SNLI multi-verbalizers*********')
        elif self.args.task_name == 'QNLI':
            multi_verb = get_multi_verb(self.args.task_name, self.args.seed)
            multi_interest_index = []
            
            for verb in multi_verb['not_entailment']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['entailment']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :5].mean(dim=1)
            c1 = multi_logits[:, 5:10].mean(dim=1)
            logits = torch.stack([c0, c1]).T
            # print('*******Use QNLI multi-verbalizers*********')
        elif self.args.task_name == 'QQP':
            multi_verb = get_multi_verb(self.args.task_name, self.args.seed)
            multi_interest_index = []
            
            for verb in multi_verb['No']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['Yes']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :5].mean(dim=1)
            c1 = multi_logits[:, 5:10].mean(dim=1)
            logits = torch.stack([c0, c1]).T
            # print('*******Use QQP multi-verbalizers*********')
        elif self.args.task_name == 'DBPedia':
            # multi_verb = get_multi_verb(self.args.task_name, self.args.seed)
            multi_interest_index = []
            
            multi_interest_index.append(self.tokenizer.encode("Company")[1])
            multi_interest_index.append(self.tokenizer.encode("Records")[1])
            multi_interest_index.append(self.tokenizer.encode("Group")[1])
            multi_interest_index.append(self.tokenizer.encode("Corporation")[1])
            multi_interest_index.append(self.tokenizer.encode("Bank")[1])

            multi_interest_index.append(self.tokenizer.encode("Education")[1])
            multi_interest_index.append(self.tokenizer.encode("School")[1])
            multi_interest_index.append(self.tokenizer.encode("College")[1])
            multi_interest_index.append(self.tokenizer.encode("University")[1])
            multi_interest_index.append(self.tokenizer.encode("Academy")[1])

            multi_interest_index.append(self.tokenizer.encode("Artist")[1])
            multi_interest_index.append(self.tokenizer.encode("Musician")[1])
            multi_interest_index.append(self.tokenizer.encode("Singer")[1])
            multi_interest_index.append(self.tokenizer.encode("Writer")[1])
            multi_interest_index.append(self.tokenizer.encode("Author")[1])

            multi_interest_index.append(self.tokenizer.encode("Athlete")[1])
            multi_interest_index.append(self.tokenizer.encode("Footballer")[1])
            multi_interest_index.append(self.tokenizer.encode("Baseball")[1])
            multi_interest_index.append(self.tokenizer.encode("Cricketer")[1])
            multi_interest_index.append(self.tokenizer.encode("American")[1])

            multi_interest_index.append(self.tokenizer.encode("Office")[1])
            multi_interest_index.append(self.tokenizer.encode("Politician")[1])
            multi_interest_index.append(self.tokenizer.encode("Statesman")[1])
            multi_interest_index.append(self.tokenizer.encode("Minister")[1])
            multi_interest_index.append(self.tokenizer.encode("Officer")[1])

            multi_interest_index.append(self.tokenizer.encode("Transportation")[1])
            multi_interest_index.append(self.tokenizer.encode("USS")[1])
            multi_interest_index.append(self.tokenizer.encode("HMS")[1])
            multi_interest_index.append(self.tokenizer.encode("SS")[1])
            multi_interest_index.append(self.tokenizer.encode("Ship")[1])

            multi_interest_index.append(self.tokenizer.encode("Building")[1])
            multi_interest_index.append(self.tokenizer.encode("House")[1])
            multi_interest_index.append(self.tokenizer.encode("District")[1])
            multi_interest_index.append(self.tokenizer.encode("Historic")[1])
            multi_interest_index.append(self.tokenizer.encode("Hospital")[1])

            multi_interest_index.append(self.tokenizer.encode("Natural")[1])
            multi_interest_index.append(self.tokenizer.encode("River")[1])
            multi_interest_index.append(self.tokenizer.encode("Lake")[1])
            multi_interest_index.append(self.tokenizer.encode("Mountain")[1])
            multi_interest_index.append(self.tokenizer.encode("Creek")[1])

            multi_interest_index.append(self.tokenizer.encode("Village")[1])
            multi_interest_index.append(self.tokenizer.encode("Voivodeship")[1])
            multi_interest_index.append(self.tokenizer.encode("Country")[1])
            multi_interest_index.append(self.tokenizer.encode("Poland")[1])
            multi_interest_index.append(self.tokenizer.encode("West")[1])

            multi_interest_index.append(self.tokenizer.encode("Animal")[1])
            multi_interest_index.append(self.tokenizer.encode("Horse")[1])
            multi_interest_index.append(self.tokenizer.encode("Mouse")[1])
            multi_interest_index.append(self.tokenizer.encode("Bat")[1])
            multi_interest_index.append(self.tokenizer.encode("Frog")[1])

            multi_interest_index.append(self.tokenizer.encode("Plant")[1])
            multi_interest_index.append(self.tokenizer.encode("Bulbophyllum")[1])
            multi_interest_index.append(self.tokenizer.encode("Tillandsia")[1])
            multi_interest_index.append(self.tokenizer.encode("Ulmus")[1])
            multi_interest_index.append(self.tokenizer.encode("Buddleja")[1])

            multi_interest_index.append(self.tokenizer.encode("Album")[1])
            multi_interest_index.append(self.tokenizer.encode("Music")[1])
            multi_interest_index.append(self.tokenizer.encode("Live")[1])
            multi_interest_index.append(self.tokenizer.encode("Hits")[1])
            multi_interest_index.append(self.tokenizer.encode("Soundtrack")[1])

            multi_interest_index.append(self.tokenizer.encode("Film")[1])
            multi_interest_index.append(self.tokenizer.encode("Love")[1])
            multi_interest_index.append(self.tokenizer.encode("Story")[1])
            multi_interest_index.append(self.tokenizer.encode("Night")[1])
            multi_interest_index.append(self.tokenizer.encode("Girl")[1])

            multi_interest_index.append(self.tokenizer.encode("Written")[1])
            multi_interest_index.append(self.tokenizer.encode("Journal")[1])
            multi_interest_index.append(self.tokenizer.encode("Magazine")[1])
            multi_interest_index.append(self.tokenizer.encode("Book")[1])
            multi_interest_index.append(self.tokenizer.encode("Novel")[1])
            
            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :5].mean(dim=1)
            c1 = multi_logits[:, 5:10].mean(dim=1)
            c2 = multi_logits[:, 10:15].mean(dim=1)
            c3 = multi_logits[:, 15:20].mean(dim=1)
            c4 = multi_logits[:, 20:25].mean(dim=1)
            c5 = multi_logits[:, 25:30].mean(dim=1)
            c6 = multi_logits[:, 30:35].mean(dim=1)
            c7 = multi_logits[:, 35:40].mean(dim=1)
            c8 = multi_logits[:, 40:45].mean(dim=1)
            c9 = multi_logits[:, 45:50].mean(dim=1)
            c10 = multi_logits[:, 50:55].mean(dim=1)
            c11 = multi_logits[:, 55:60].mean(dim=1)
            c12 = multi_logits[:, 60:65].mean(dim=1)
            c13 = multi_logits[:, 65:].mean(dim=1)
            logits = torch.stack([c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13]).T
            # print('*******Use DBPedia multi-verbalizers*********')
        elif self.args.task_name == 'AGNews':
            multi_verb = get_multi_verb(self.args.task_name, self.args.seed)
            multi_interest_index = []
            
            for verb in multi_verb['World']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['Sports']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['Business']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['Technology']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            
            # multi_interest_index.append(self.tokenizer.encode("World")[1])
            # multi_interest_index.append(self.tokenizer.encode("Iran")[1])
            # multi_interest_index.append(self.tokenizer.encode("Iraq")[1])
            # multi_interest_index.append(self.tokenizer.encode("Regional")[1])
            # multi_interest_index.append(self.tokenizer.encode("BuzzFeed")[1])
            # multi_interest_index.append(self.tokenizer.encode("PM")[1])

            # multi_interest_index.append(self.tokenizer.encode("Sports")[1])
            # multi_interest_index.append(self.tokenizer.encode("Athletics")[1])
            # multi_interest_index.append(self.tokenizer.encode("Hockey")[1])
            # multi_interest_index.append(self.tokenizer.encode("Sporting")[1])
            # multi_interest_index.append(self.tokenizer.encode("Basketball")[1])
            # multi_interest_index.append(self.tokenizer.encode("TEAM")[1])

            # multi_interest_index.append(self.tokenizer.encode("Business")[1])
            # multi_interest_index.append(self.tokenizer.encode("Investment")[1])
            # multi_interest_index.append(self.tokenizer.encode("Trade")[1])
            # multi_interest_index.append(self.tokenizer.encode("Industry")[1])
            # multi_interest_index.append(self.tokenizer.encode("ET")[1])
            # multi_interest_index.append(self.tokenizer.encode("business")[1])

            # multi_interest_index.append(self.tokenizer.encode("Technology")[1])
            # multi_interest_index.append(self.tokenizer.encode("tech")[1])
            # multi_interest_index.append(self.tokenizer.encode("technology")[1])
            # multi_interest_index.append(self.tokenizer.encode("Tech")[1])
            # multi_interest_index.append(self.tokenizer.encode("Mobile")[1])
            # multi_interest_index.append(self.tokenizer.encode("Wired")[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :5].mean(dim=1)
            c1 = multi_logits[:, 5:10].mean(dim=1)
            c2 = multi_logits[:, 10:15].mean(dim=1)
            c3 = multi_logits[:, 15:].mean(dim=1)
            logits = torch.stack([c0, c1, c2, c3]).T
            # print('*******Use AGNews multi-verbalizers*********')
        elif self.args.task_name == 'MRPC':
            multi_verb = get_multi_verb(self.args.task_name, self.args.seed)
            multi_interest_index = []
            
            for verb in multi_verb['No']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['Yes']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            
            # multi_interest_index.append(self.tokenizer.encode("No")[1])
            # multi_interest_index.append(self.tokenizer.encode("Still")[1])
            # multi_interest_index.append(self.tokenizer.encode("meanwhile")[1])
            # multi_interest_index.append(self.tokenizer.encode("Finally")[1])
            # multi_interest_index.append(self.tokenizer.encode("Actually")[1])
            # multi_interest_index.append(self.tokenizer.encode("Later")[1])

            # multi_interest_index.append(self.tokenizer.encode("Yes")[1])
            # multi_interest_index.append(self.tokenizer.encode("Furthermore")[1])
            # multi_interest_index.append(self.tokenizer.encode("Thankfully")[1])
            # multi_interest_index.append(self.tokenizer.encode("Instead")[1])
            # multi_interest_index.append(self.tokenizer.encode("Rather")[1])
            # multi_interest_index.append(self.tokenizer.encode("The")[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :5].mean(dim=1)
            c1 = multi_logits[:, 5:].mean(dim=1)
            logits = torch.stack([c0, c1]).T
            # print('*******Use MRPC multi-verbalizers*********')
        elif self.args.task_name in ['sst2', 'Yelp']:
            multi_verb = get_multi_verb(self.args.task_name, self.args.seed)
            multi_interest_index = []
            
            for verb in multi_verb['negative']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])
            for verb in multi_verb['positive']:
                multi_interest_index.append(self.tokenizer.encode(verb)[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :5].mean(dim=1)
            c1 = multi_logits[:, 5:].mean(dim=1)
            logits = torch.stack([c0, c1]).T
            # print('*******Use sst2 or Yelp multi-verbalizers*********')
        else:
            NotImplementedError        

        label_map = self.metric.label_map

        converted_target = target.clone()
        for key, val in label_map.items():
            converted_target[target == key] = val
        # interest_index = list(label_map.keys())
        # logits = logits[:, interest_index]
        pred = logits.argmax(dim=-1)

        if self.metric_key == 'acc':
            perf = (pred == converted_target).sum() / len(target)
        elif self.metric_key == 'f1':
            perf = f1_score(converted_target.detach().cpu().numpy().tolist(),
                            pred.detach().cpu().numpy().tolist(), average='macro')
        else:
            raise KeyError(f'[Metric] Only support [acc, f1], got {self.metric_key} instead.')

        if self.loss_type == 'hinge':
            loss = hinge_loss(logits, converted_target, margin=self.margin, reduction='sum').item() / len(target)
        elif self.loss_type == 'ce':
            loss = self.ce_loss(logits, converted_target).item()
        elif self.loss_type == 'perf':
            loss = -1 * perf
        else:
            raise KeyError(f'[Loss] Only support [hinge, ce, perf], got {self.loss_type} instead.')

        return loss, perf

    
    def eval(self, prompt_embedding=None, layer_id=None, test_data=None):
        self.num_call += 1
        best_prefix = self.best_prefix.clone()
        if prompt_embedding is not None:
            prompt_embedding = torch.tensor(prompt_embedding).type(torch.float32)  # z
            prompt_embedding = self.linear[layer_id](prompt_embedding).reshape(-1, self.config.hidden_size)  # Az
            best_prefix[layer_id] = prompt_embedding

        self.model.set_prompt_embedding(best_prefix)

        for k, v in train_data.items():
            train_data[k] = v.to(device)
        with torch.no_grad():
            if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
                outputs = self.model(
                    input_ids=train_data['input_ids'],
                    attention_mask=train_data['attention_mask'],
                    decoder_input_ids=train_data['decoder_input_ids'],
                    decoder_attention_mask=train_data['decoder_attention_mask'],
                )
            elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
                outputs = self.model(
                    input_ids=train_data['input_ids'],
                    attention_mask=train_data['attention_mask'],
                )
            else:
                outputs = self.model(
                    input_ids=train_data['input_ids'],
                    attention_mask=train_data['attention_mask'],
                    mask_pos=train_data['mask_pos'],
                )
            logits = outputs['logits']
            if random_proj == 'normal' and len(self.intermediate_stats) == 1:
                # if is the first forward pass, record the range of hidden states of each layer
                print('Calculating std for random projections...')
                if self.model_name in ['facebook/bart-base', 'facebook/bart-large',
                                        't5-small', 't5-base', 't5-large', 't5-3b',
                                        'fnlp/cpt-large',
                                        ]:
                    hidden_states = outputs['encoder_hidden_states']
                else:
                    hidden_states = outputs['hidden_states']
                for i, h in enumerate(hidden_states[1:-1]):
                    if save_hiddens:
                        hid_path = './hidstates/{}'.format(self.model_name.split('/')[-1])
                        if not os.path.exists(hid_path):
                            os.makedirs(hid_path, exist_ok=True)
                        with open('{}/hidden_{}.bin'.format(hid_path, i + 1), 'wb') as f:
                            pickle.dump(h, f)
                    print('[Layer {}]'.format(i + 1))
                    hidden = h.clone().reshape(-1).detach().cpu().numpy()
                    mu_hat = np.mean(hidden)
                    std_hat = np.std(hidden)
                    max_h = np.max(hidden)
                    min_h = np.min(hidden)
                    print(' - Before clipping: mu=%.4f, std=%.4f, min=%.4f, max=%.4f' % (
                        mu_hat, std_hat, min_h, max_h))
                    # Clipping outliers
                    clip_round = 0
                    while clip_round < 5:
                        clip_round += 1
                        min_bound = mu_hat - 3 * std_hat
                        max_bound = mu_hat + 3 * std_hat
                        hidden = np.clip(hidden, min_bound, max_bound)
                        mu_hat = np.mean(hidden)
                        std_hat = np.std(hidden)
                        max_h = np.max(hidden)
                        min_h = np.min(hidden)
                        print(' - After clipping (round %d): mu=%.4f, std=%.4f, min=%.4f, max=%.4f' % (
                            clip_round, mu_hat, std_hat, min_h, max_h))
                    # Calculating std dev for the random projection
                    mu = 0.0
                    std = std_hat / (np.sqrt(intrinsic_dim) * args.sigma1)
                    print(' - Random Projection: mu=%.4f, std=%.4f' % (mu, std))
                    for p in self.linear[i + 1].parameters():
                        torch.nn.init.normal_(p, mu, std)
                    self.intermediate_stats.append((mu, std))
                assert len(self.intermediate_stats) == self.config.num_hidden_layers
                self.model.config.output_hidden_states = None
                print('Random projections initialized.')

            if self.args.multiVerbalizer:
                loss, perf = self.calc_metric_for_multiVerbalizer(logits, train_data['labels'])
            else:
                loss, perf = self.calc_metric(logits, train_data['labels'])

            if perf > self.best_train_perf:
                self.best_train_perf = perf

            if self.num_call % self.print_every == 0:
                print(
                    '[# API Calls {}] loss: {}. Current perf: {}. Best perf so far: {}'.format(
                        self.num_call,
                        round(float(loss), 4),
                        round(float(perf), 4),
                        round(float(self.best_train_perf), 4)))

            if self.num_call % self.eval_every == 0 and self.num_call >= 8000:
                print('********* Evaluated on dev set *********')
                if len(dev_data['input_ids'].shape) == 3:
                    batch_num = int(args.dev_sample_num / self.args.dev_batch_size)
                    # for k, v in dev_data.items():
                    #     dev_data[k] = torch.squeeze(v[:args.dev_sample_num].view(batch_num, self.args.dev_batch_size, -1))
                    dev_loss = 0
                    dev_perf = 0
                    for i in tqdm.tqdm(range(batch_num)):
                        epoch_dev_data = {}
                        for k, v in dev_data.items():
                            epoch_dev_data[k] = v[i].to(device)
                        with torch.no_grad():
                            if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
                                logits = self.model(
                                    input_ids=epoch_dev_data['input_ids'],
                                    attention_mask=epoch_dev_data['attention_mask'],
                                    decoder_input_ids=epoch_dev_data['decoder_input_ids'],
                                    decoder_attention_mask=epoch_dev_data['decoder_attention_mask'],
                                )['logits']
                            elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
                                logits = self.model(
                                    input_ids=epoch_dev_data['input_ids'],
                                    attention_mask=epoch_dev_data['attention_mask'],
                                )['logits']
                            else:
                                logits = self.model(
                                    input_ids=epoch_dev_data['input_ids'],
                                    attention_mask=epoch_dev_data['attention_mask'],
                                    mask_pos=epoch_dev_data['mask_pos'],
                                )['logits']

                        if self.args.multiVerbalizer:
                            epoch_dev_loss, epoch_dev_perf = self.calc_metric_for_multiVerbalizer(logits, epoch_dev_data['labels'])
                        else:
                            epoch_dev_loss, epoch_dev_perf = self.calc_metric(logits, epoch_dev_data['labels'])
                        dev_loss += epoch_dev_loss
                        dev_perf += epoch_dev_perf
                    dev_loss /= batch_num
                    dev_perf /= batch_num

                    if dev_perf > self.best_dev_perf:
                        self.is_better_dev[layer_id] = 1
                        self.best_dev_perf = dev_perf
                        self.best = best_prefix.clone()#torch.Size([24, 50, 1024])
                        print("###self.num_call:",self.num_call)
                        # print("###dev_perf > self.best_dev_perf,dev_perf ,self.best_dev_perf:",dev_perf ,self.best_dev_perf)

                    print('Dev loss: {}. Dev perf: {}. Best dev perf: {}'.format(
                        round(float(dev_loss), 4),
                        round(float(dev_perf), 4),
                        round(float(self.best_dev_perf), 4)))
                    print('********* Done *********')
                else:
                    for k, v in dev_data.items():
                        dev_data[k] = v.to(device)
                    with torch.no_grad():
                        if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
                            logits = self.model(
                                input_ids=dev_data['input_ids'],
                                attention_mask=dev_data['attention_mask'],
                                decoder_input_ids=dev_data['decoder_input_ids'],
                                decoder_attention_mask=dev_data['decoder_attention_mask'],
                            )['logits']
                        elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
                            logits = self.model(
                                input_ids=dev_data['input_ids'],
                                attention_mask=dev_data['attention_mask'],
                            )['logits']
                        else:
                            logits = self.model(
                                input_ids=dev_data['input_ids'],
                                attention_mask=dev_data['attention_mask'],
                                mask_pos=dev_data['mask_pos'],
                            )['logits']

                    if self.args.multiVerbalizer:
                        dev_loss, dev_perf = self.calc_metric_for_multiVerbalizer(logits, dev_data['labels'])
                    else:
                        dev_loss, dev_perf = self.calc_metric(logits, dev_data['labels'])

                    if dev_perf > self.best_dev_perf:
                        self.is_better_dev[layer_id] = 1
                        self.best_dev_perf = dev_perf
                        self.best = best_prefix.clone()#torch.Size([24, 50, 1024])
                        print("###self.num_call:",self.num_call)
                        # print("###dev_perf > self.best_dev_perf,dev_perf ,self.best_dev_perf:",dev_perf ,self.best_dev_perf)

                    print('Dev loss: {}. Dev perf: {}. Best dev perf: {}'.format(
                        round(float(dev_loss), 4),
                        round(float(dev_perf), 4),
                        round(float(self.best_dev_perf), 4)))
                    print('********* Done *********')
        return loss

    def refresh_is_better_dev(self, layer_id = None):
        self.is_better_dev[layer_id] = 0
        return self.is_better_dev[layer_id]


if model_name in ['roberta-base', 'roberta-large']:
    tokenizer = RobertaTokenizer.from_pretrained(model_path)
elif model_name in ['bert-base-uncased', 'bert-large-uncased', 'fnlp/cpt-large']:
    tokenizer = BertTokenizer.from_pretrained(model_path)
elif model_name in ['facebook/bart-base', 'facebook/bart-large']:
    tokenizer = BartTokenizer.from_pretrained(model_path)
elif model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
    tokenizer = T5Tokenizer.from_pretrained(model_path)
elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
    tokenizer = GPT2Tokenizer.from_pretrained(model_path)
else:
    raise NotImplementedError

cache_fn = f"caches/data_{model_name.replace('/', '-')}_{data_dir}_{task_name}_{n_prompt_tokens}_{seed}.pt"

DataLoader = {
    'sst2': SST2Loader,
    'AGNews': AGNewsLoader,
    'Yelp': YelpPLoader,
    'MRPC': MRPCLoader,
    'SNLI': SNLILoader,
    'TREC': TRECLoader,
    'QNLI': QNLILoader,
    'QQP': QQPLoader,
    'DBPedia': DBPediaLoader,
}

@cache_results(cache_fn, _refresh=True)
def get_data(task_name, tokenizer):
    splits = ['train', 'dev']
    data_bundle = DataLoader[task_name](tokenizer=tokenizer, n_prompt_tokens=n_prompt_tokens, data_dir=data_dir, args=args).my_load(splits, seed)
    return data_bundle

data_bundle = get_data(task_name=task_name, tokenizer=tokenizer)
train_data, dev_data = data_bundle.get_dataset('train'), data_bundle.get_dataset('dev')

for ds in [train_data, dev_data]:
    ds.set_pad_val('input_ids', tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0)
    ds.set_pad_val('attention_mask', 0)

print(args)
print('# of train data: {}'.format(len(train_data)))
print('Example:')
print(train_data[0])
print('\n# of dev data: {}'.format(len(dev_data)))
print('Example:')
print(dev_data[0])

if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
    train_data = {
        'input_ids': torch.tensor(train_data['input_ids'].get(list(range(len(train_data))))),
        'attention_mask': torch.tensor(train_data['attention_mask'].get(list(range(len(train_data))))),
        'decoder_input_ids': torch.tensor(train_data['decoder_input_ids'].get(list(range(len(train_data))))),
        'decoder_attention_mask': torch.tensor(train_data['decoder_attention_mask'].get(list(range(len(train_data))))),
        'labels': torch.tensor(train_data['labels'].get(list(range(len(train_data))))),
    }
    dev_data = {
        'input_ids': torch.tensor(dev_data['input_ids'].get(list(range(len(dev_data))))),
        'attention_mask': torch.tensor(dev_data['attention_mask'].get(list(range(len(dev_data))))),
        'decoder_input_ids': torch.tensor(dev_data['decoder_input_ids'].get(list(range(len(dev_data))))),
        'decoder_attention_mask': torch.tensor(dev_data['decoder_attention_mask'].get(list(range(len(dev_data))))),
        'labels': torch.tensor(dev_data['labels'].get(list(range(len(dev_data))))),
    }
elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
    train_data = {
        'input_ids': torch.tensor(train_data['input_ids'].get(list(range(len(train_data))))),
        'attention_mask': torch.tensor(train_data['attention_mask'].get(list(range(len(train_data))))),
        'labels': torch.tensor(train_data['labels'].get(list(range(len(train_data))))),
    }
    dev_data = {
        'input_ids': torch.tensor(dev_data['input_ids'].get(list(range(len(dev_data))))),
        'attention_mask': torch.tensor(dev_data['attention_mask'].get(list(range(len(dev_data))))),
        'labels': torch.tensor(dev_data['labels'].get(list(range(len(dev_data))))),
    }
else:
    train_data = {
        'input_ids': torch.tensor(train_data['input_ids'].get(list(range(len(train_data))))),
        'attention_mask': torch.tensor(train_data['attention_mask'].get(list(range(len(train_data))))),
        'mask_pos': torch.tensor(train_data['mask_pos'].get(list(range(len(train_data))))),
        'labels': torch.tensor(train_data['labels'].get(list(range(len(train_data))))),
    }
    dev_data = {
        'input_ids': torch.tensor(dev_data['input_ids'].get(list(range(len(dev_data))))),
        'attention_mask': torch.tensor(dev_data['attention_mask'].get(list(range(len(dev_data))))),
        'mask_pos': torch.tensor(dev_data['mask_pos'].get(list(range(len(dev_data))))),
        'labels': torch.tensor(dev_data['labels'].get(list(range(len(dev_data))))),
    }

if dev_data['input_ids'].shape[0] > args.dev_batch_size:
    batch_num = int(args.dev_sample_num / args.dev_batch_size)
    for k, v in dev_data.items():
        dev_data[k] = torch.squeeze(v[:args.dev_sample_num].view(batch_num, args.dev_batch_size, -1))

model_forward_api = LMForwardAPI(
    model_name=model_name,
    model_path=model_path,
    n_prompt_tokens=n_prompt_tokens,
    task_name=task_name,
    loss_type=loss_type,
    args=args,
)

cma_opts = {
    'seed': seed,
    'popsize': popsize,
    'maxiter': budget // (popsize * model_forward_api.config.num_hidden_layers),
    'verbose': -1,
}
if bound > 0:
    cma_opts['bounds'] = [-1 * bound, 1 * bound]

if args.sigma_setting == 'bbt2':
    sigmas = [sigma1]
    for i in range(model_forward_api.config.num_hidden_layers - 1):
        sigmas.append(sigma2)
elif args.sigma_setting == 'lin':
    sigmas = [sigma1]
    diff = (sigma1 - sigma2) / (model_forward_api.config.num_hidden_layers - 1)
    for i in range(1, model_forward_api.config.num_hidden_layers):
        sigmas.append(sigma1 - diff * i)
elif args.sigma_setting == 'exp':
    sigmas = [sigma1]
    diff = sigma1 - sigma2
    for i in range(1, model_forward_api.config.num_hidden_layers):
        sigmas.append(np.exp(-i/5) * diff + sigma2)
assert len(sigmas) == model_forward_api.config.num_hidden_layers
es_list = [
    cma.CMAEvolutionStrategy(intrinsic_dim * [0], sigmas[i], inopts=cma_opts)
    for i in range(model_forward_api.config.num_hidden_layers)
]

if budget2 == 0:
    start_time = time.time()

    for _ in range(budget // (int(popsize) * model_forward_api.config.num_hidden_layers)):
        for i, es in enumerate(es_list):
            solutions = es.ask()
            fitnesses = [model_forward_api.eval(x, i) for x in solutions]
            es.tell(solutions, fitnesses)
            model_forward_api.best_prefix[i] = model_forward_api.linear[i](
                torch.tensor(es.result.xbest).type(torch.float32)).reshape(-1,
                                                                        model_forward_api.config.hidden_size)  # set best cv
        # if _  % 2 == 0:
        #     epoch_num = _ * (int(popsize) * model_forward_api.config.num_hidden_layers)
        #     if not os.path.exists(f'./{prefix}/{epoch_num}_results/{task_name}/{seed}'):
        #         os.makedirs(f'./{prefix}/{epoch_num}_results/{task_name}/{seed}')
        #     torch.save(model_forward_api.best_prefix, f=f'./{prefix}/{epoch_num}_results/{task_name}/{seed}/best.pt')


    end_time = time.time()
    print('Done. Elapsed time: {} (mins)'.format((end_time - start_time) / 60))
    prefix = 'ins{}_con{}_mul{}_loss{}_s1{}_s2{}'.format(args.instruction, args.in_contexts, args.multiVerbalizer, args.loss_type, args.sigma1, args.sigma2)
    if not os.path.exists(f'./{prefix}/last_epoch_results/{task_name}/{seed}'):
        os.makedirs(f'./{prefix}/last_epoch_results/{task_name}/{seed}')

    if not os.path.exists(f'./{prefix}/dev_best_results/{task_name}/{seed}'):
        os.makedirs(f'./{prefix}/dev_best_results/{task_name}/{seed}')
    # parser.add_argument("--instruction", default=False, action='store_true', help="")
    # parser.add_argument("--in_contexts", default=False, action='store_true', help="")
    # parser.add_argument("--multiVerbalizer", default=False, action='store_true', help="multi Verbalizer for TREC.")
    torch.save(model_forward_api.best, f=f'./{prefix}/dev_best_results/{task_name}/{seed}/best.pt')
    torch.save(model_forward_api.best_prefix, f=f'./{prefix}/last_epoch_results/{task_name}/{seed}/best.pt')

else:
    start_time = time.time()

    # es.optimize(model_forward_api.eval)
    # #this func executes the same way the loop below, and calls lots time of eval api
    result = model_forward_api.config.num_hidden_layers * [0]
    best_result = model_forward_api.config.num_hidden_layers * [0]
    for round_ in range(budget // (int(popsize) * model_forward_api.config.num_hidden_layers)):
        for i, es in enumerate(es_list):# i refers to layer_num, 0->24 0>24 ...
            print("layer i:",i)
            solutions = es.ask()
            #ask delivers new candidate solutions and tell updates the optim instance by passing the respective function values
            fitnesses = [model_forward_api.eval(x, i) for x in solutions]
            #every time we call eval (per 20 popsize), print loss
            #serial20fitnesses
            es.tell(solutions, fitnesses)
            result[i] = es.result#[0]:solution [1]:best f value [2]
            # print("i,result[i][1]:",i,result[i][1])
            # print("fitness_list[0]:",fitnesses[0])
            # model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(result[i].xbest).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
            #ndarray(500,1) to torch.Size([51200]) to torch.Size([50, 1024])
            
            if round_ == 0:
                best_result[i] = result[i][5] if pop_mean else result[i][0]
                # model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(best_result[i]).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
                model_forward_api.refresh_is_better_dev(i)
            else:
                if model_forward_api.is_better_dev[i]:
                    print("###is_better_dev")
                    best_result[i] = result[i][5] if pop_mean else result[i][0]
                    model_forward_api.refresh_is_better_dev(i)
            model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(result[i][0]).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv

        if round_ % 2 == 0:
            epoch_num = round_ * (int(popsize) * model_forward_api.config.num_hidden_layers)
            if not os.path.exists(f'./{prefix}/{epoch_num}_results/{task_name}/{seed}'):
                os.makedirs(f'./{prefix}/{epoch_num}_results/{task_name}/{seed}')
            torch.save(model_forward_api.best_prefix, f=f'./{prefix}/{epoch_num}_results/{task_name}/{seed}/best.pt')


    print("finish CMA. start 2nd stage DFO")
    for i in range(model_forward_api.config.num_hidden_layers):# i refers to layer_num #0->..->0,...,24-->..->24
        print("layer i:",i)
        max_iter=budget2 // model_forward_api.config.num_hidden_layers
        def short_api(x_):#[500,1] to [20]
            fitness = model_forward_api.eval(x_,i)
            return fitness

        options={}
        for methods in ['Powell','Nelder-Mead']:#, "maxfev": 100 powell do not need seed
            options[methods]={"disp": True, "maxfev":max_iter}
        for methods in ['BFGS','SLSQP','L-BFGS-B']:#, "maxiter": 80/200
            options[methods]={"disp": True, "maxiter":max_iter}
        for methods in ['COBYLA']:
            options[methods]={"disp": False,"maxiter":max_iter}
        # options['Powell'].update({"ftol": 1e-26}) 
        # options['Nelder-Mead'].update({"ftol": 1e-26})
        # options['COBYLA'].update({"tol": 1e-25})
        # options['BFGS'].update({"gtol": 1e-5})
        # options['SLSQP'].update({"ftol": 1e-26})

        start_time = time.time()
        def callback_f(x_):
            print("i,fitness:",i,short_api(x_))
            model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(x_).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
        res = minimize(short_api,  best_result[i],  method=replace_alg,callback=callback_f, options=options[replace_alg])
        print("layer,loss(fitnesses):",i,res.fun)

        # if i % 1000 == 0:
        #     epoch_num = i + 8000
        #     if not os.path.exists(f'./{prefix}/{epoch_num}_results/{task_name}/{seed}'):
        #         os.makedirs(f'./{prefix}/{epoch_num}_results/{task_name}/{seed}')
        #     torch.save(model_forward_api.best_prefix, f=f'./{prefix}/{epoch_num}_results/{task_name}/{seed}/best.pt')

    end_time = time.time()
    print('Done. Elapsed time: {} (mins)'.format((end_time - start_time) / 60))
    if not os.path.exists(f'./{prefix}/last_epoch_results/{task_name}/{seed}'):
        os.makedirs(f'./{prefix}/last_epoch_results/{task_name}/{seed}')

    if not os.path.exists(f'./{prefix}/dev_best_results/{task_name}/{seed}'):
        os.makedirs(f'./{prefix}/dev_best_results/{task_name}/{seed}')

    torch.save(model_forward_api.best, f=f'./{prefix}/dev_best_results/{task_name}/{seed}/best.pt')
    torch.save(model_forward_api.best_prefix, f=f'./{prefix}/last_epoch_results/{task_name}/{seed}/best.pt')
    
    '''
    Powell
    # start_time = time.time()

    # # es.optimize(model_forward_api.eval)
    # # #this func executes the same way the loop below, and calls lots time of eval api
    # result = model_forward_api.config.num_hidden_layers * [0]
    # best_result = model_forward_api.config.num_hidden_layers * [0]
    # for round_ in range(budget // (int(popsize) * model_forward_api.config.num_hidden_layers)):
    #     for i, es in enumerate(es_list):# i refers to layer_num, 0->24 0>24 ...
    #         print("layer i:",i)
    #         solutions = es.ask()
    #         #ask delivers new candidate solutions and tell updates the optim instance by passing the respective function values
    #         fitnesses = [model_forward_api.eval(x, i) for x in solutions]
    #         #every time we call eval (per 20 popsize), print loss
    #         #serial20fitnesses
    #         es.tell(solutions, fitnesses)
    #         result[i] = es.result#[0]:solution [1]:best f value [2]
    #         # print("i,result[i][1]:",i,result[i][1])
    #         # print("fitness_list[0]:",fitnesses[0])
    #         # model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(result[i].xbest).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
    #         #ndarray(500,1) to torch.Size([51200]) to torch.Size([50, 1024])
            
    #         if round_ == 0:
    #             best_result[i] = result[i][5] if pop_mean else result[i][0]
    #             model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(best_result[i]).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
    #             model_forward_api.refresh_is_better_dev(i)
    #         else:
    #             if model_forward_api.is_better_dev[i]:
    #                 print("###is_better_dev")
    #                 best_result[i] = result[i][5] if pop_mean else result[i][0]
    #                 model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(best_result[i]).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
    #                 model_forward_api.refresh_is_better_dev(i)
    # #         if i==len(es_list)-1:
    # #             es.logger.add()  # write data to disc to be plotted
    # #             es.disp()
    # # es_list[-1].logger.plot()
    # # savefig("./cmaplot.png")

    # print("finish CMA. start 2nd stage DFO")
    # for i in range(model_forward_api.config.num_hidden_layers):# i refers to layer_num #0->..->0,...,24-->..->24
    #     print("layer i:",i)
    #     max_iter=budget2 // model_forward_api.config.num_hidden_layers
    #     def short_api(x_):#[500,1] to [20]
    #         fitness = model_forward_api.eval(x_,i)
    #         return fitness

    #     options={}
    #     for methods in ['Powell','Nelder-Mead']:#, "maxfev": 100 powell do not need seed
    #         options[methods]={"disp": True, "maxfev":max_iter}
    #     for methods in ['BFGS','SLSQP','L-BFGS-B']:#, "maxiter": 80/200
    #         options[methods]={"disp": True, "maxiter":max_iter}
    #     for methods in ['COBYLA']:
    #         options[methods]={"disp": True,"maxiter":max_iter}
    #     options['Powell'].update({"ftol": 1e-26}) 
    #     options['Nelder-Mead'].update({"ftol": 1e-26})
    #     options['COBYLA'].update({"tol": 1e-25})
    #     options['BFGS'].update({"gtol": 1e-5})
    #     options['SLSQP'].update({"ftol": 1e-26})

    #     start_time = time.time()
    #     res = minimize(short_api,  best_result[i],  method=replace_alg, options=options[replace_alg])
    #     if model_forward_api.is_better_dev[i]:
    #         print("###is_better_dev")
    #         model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(res.x).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
    #         model_forward_api.refresh_is_better_dev(i)
    #     print("layer,loss(fitnesses):",i,res.fun)


    # end_time = time.time()
    # print('Done. Elapsed time: {} (mins)'.format((end_time - start_time) / 60))
    # if not os.path.exists(f'./{prefix}/last_epoch_results/{task_name}/{seed}'):
    #     os.makedirs(f'./{prefix}/last_epoch_results/{task_name}/{seed}')

    # if not os.path.exists(f'./{prefix}/dev_best_results/{task_name}/{seed}'):
    #     os.makedirs(f'./{prefix}/dev_best_results/{task_name}/{seed}')

    # torch.save(model_forward_api.best, f=f'./{prefix}/dev_best_results/{task_name}/{seed}/best.pt')
    # torch.save(model_forward_api.best_prefix, f=f'./{prefix}/last_epoch_results/{task_name}/{seed}/best.pt')
    '''